# Preprocesamiento y OrganizaciÃ³n del Dataset de ImÃ¡genes

Este proyecto tiene como objetivo desarrollar un modelo de red neuronal convolucional (CNN) para clasificar imÃ¡genes de escenas naturales utilizando el Intel Image Classification Dataset. Este conjunto de datos, disponible en Kaggle, contiene aproximadamente 25,000 imÃ¡genes de 150x150 pÃ­xeles divididas en seis categorÃ­as: buildings, forest, glacier, mountain, sea y street. El objetivo es entrenar, evaluar y optimizar un modelo CNN en TensorFlow/Keras, con un flujo de trabajo que incluye preprocesamiento, aumento de datos, entrenamiento, evaluaciÃ³n, visualizaciÃ³n de resultados y la capacidad de guardar y reanudar el entrenamiento del modelo. El proyecto se implementÃ³ en Google Colab, utilizando imÃ¡genes almacenadas en Google Drive.

---

## âœ… Requisitos: Semana 2

### ğŸ“ 1. GeneraciÃ³n o selecciÃ³n del set de datos

- Conjunto de datos: Se utilizÃ³ el Intel Image Classification Dataset, que contiene aproximadamente 25,000 imÃ¡genes organizadas en carpetas por clase: `buildings`, `forest`, `glacier`, `mountain`, `sea`, `street`.
- OrganizaciÃ³n: Las imÃ¡genes originalmente estaban divididas solo en carpetas de entrenamiento y prueba. Se realizÃ³ una **distribuciÃ³n manual** para crear la carpeta `valid/` (validaciÃ³n), siguiendo una proporciÃ³n aproximada de 60% (entrenamiento), 20% (validaciÃ³n) y 20% (prueba) para cada clase. AsÃ­, la estructura final quedÃ³ organizada en carpetas `train/`, `valid/` y `test/`, cada una con subcarpetas por clase.

Cada carpeta contiene subcarpetas por clase.

---

## ğŸ”§ Preprocesado de los datos

### ğŸ“ Escalamiento

Se aplicÃ³ escalamiento a todas las imÃ¡genes dividiendo los valores de pÃ­xeles entre 255:

```python
rescale=1./255
```

Esto normaliza los valores de entrada al rango [0, 1], necesario para modelos de deep learning.

### ğŸ” AumentaciÃ³n de datos (solo entrenamiento)

Para mejorar la generalizaciÃ³n del modelo y evitar overfitting, se aplicÃ³ data augmentation al conjunto de entrenamiento:

```python
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True
)
```

Esto genera versiones aumentadas de cada imagen en tiempo real durante el entrenamiento.

### ğŸ“‚ OrganizaciÃ³n de carpetas esperada

El conjunto de datos se organiza en carpetas por clase, con subcarpetas para entrenamiento, validaciÃ³n y prueba. La estructura es la siguiente:

```bash
dataset-landmark/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ buildings/
â”‚   â”œâ”€â”€ forest/
â”‚   â”œâ”€â”€ glacier/
â”‚   â”œâ”€â”€ mountain/
â”‚   â”œâ”€â”€ sea/
â”‚   â”œâ”€â”€ street/
â”œâ”€â”€ valid/
â”‚   â”œâ”€â”€ buildings/
â”‚   â”œâ”€â”€ forest/
â”‚   â”œâ”€â”€ glacier/
â”‚   â”œâ”€â”€ mountain/
â”‚   â”œâ”€â”€ sea/
â”‚   â”œâ”€â”€ street/
â””â”€â”€ test/
    â”œâ”€â”€ buildings/
    â”œâ”€â”€ forest/
    â”œâ”€â”€ glacier/
    â”œâ”€â”€ mountain/
    â”œâ”€â”€ sea/
    â”œâ”€â”€ street/
```

---

## ğŸ› ï¸ Modelo y EvaluaciÃ³n

### Arquitectura del Modelo
Se utilizÃ³ una red neuronal convolucional (CNN) para la clasificaciÃ³n de imÃ¡genes. La arquitectura del modelo se basa en capas convolucionales y densas, con funciones de activaciÃ³n ReLU y softmax.
Se utilizÃ³ la funciÃ³n de pÃ©rdida `categorical_crossentropy` y el optimizador `Adam`. La mÃ©trica de evaluaciÃ³n fue la precisiÃ³n (`accuracy`).

### Arquitectura del modelo

```python
    model = Sequential()

    # # Conv block 1: 16 filtros
    model.add(Conv2D(16, (3,3), activation='relu', padding='same',
                            input_shape=input_shape))
    model.add(MaxPooling2D((2,2)))  # reduce a 40Ã—40

    # Conv block 2: 32 filtros
    model.add(Conv2D(32, (3,3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2,2)))  # reduce a 20Ã—20

    # Conv block 3: 64 filtros
    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2,2)))  # reduce a 10Ã—10

    # Conv block 3: 64 filtros
    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2,2)))  # reduce a 10Ã—10
    
    # Conv block 3: 128 filtros
    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2,2)))  # reduce a 10Ã—10

    # AÃ±adir Dropout para reducir overfitting
    model.add(Dropout(0.3))

    # Aplanar y capa de salida
    model.add(Flatten())
    model.add(Dense(num_classes, activation='softmax'))
```

- Capas convolucionales (Conv2D) con 32, 64 y 128 filtros, activaciÃ³n ReLU.
- Capas de agrupamiento (MaxPooling2D) para reducir dimensiones.
- Capa Flatten para aplanar las caracterÃ­sticas.
- Capa de abandono (Dropout, 0.3) para prevenir sobreajuste.
- Capa de salida (Dense) con 6 neuronas y activaciÃ³n softmax para clasificaciÃ³n multiclase.

### EvaluaciÃ³n del modelo

Se utilizÃ³ el conjunto de validaciÃ³n para evaluar el rendimiento del modelo. Se reportaron mÃ©tricas como precisiÃ³n, recall y F1-score. La matriz de confusiÃ³n se generÃ³ para visualizar el rendimiento del modelo en cada clase.

## Resultados

- PrecisiÃ³n del modelo: 0.869 (86.9%)
- Recall: 0.869 (86.9%)
- F1-score: 0.869 (86.9%)

- Matriz de confusiÃ³n: Se generÃ³ una matriz de confusiÃ³n para visualizar el rendimiento del modelo en cada clase.

![Matriz de ConfusiÃ³n](image.png)

## Entregable

1. Week 2: El archivo se encuentra en este repositorio, el enlace es el siguiente:
   - [Google Collab Notebook](https://github.com/DHurtado714-itesm/tc3002b/blob/main/data-processing.ipynb)
2. Week 3: El archivo se encuentra en este repositorio, el enlace es el siguiente:
   - [Google Collab Notebook](https://github.com/DHurtado714-itesm/tc3002b/blob/main/main.ipynb)